{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d864bd2-7186-4431-9001-7f5b6b840ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd99ec0e-a0e6-497c-9354-5d354ade383b",
   "metadata": {},
   "source": [
    "# Loading images to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f22540-9d8f-4515-b041-ddbcf97c0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Resize((128, 128)),\n",
    "])\n",
    "\n",
    "# Load  dataset\n",
    "dataset_train = ImageFolder(\n",
    "\"D:\\hossam\\Deep learnig\\Intermediate Deep Learning with PyTorch\\clouds\\clouds_train\",\n",
    "transform=train_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4256382-64da-429e-865a-8d11ef6d1aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders to iterate through batches\n",
    "dataloader_train = DataLoader(\n",
    "                        dataset_train,\n",
    "                        shuffle=True,\n",
    "                        batch_size=1,\n",
    "                        )\n",
    "\n",
    "image, label = next(iter(dataloader_train))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08ad7195-ac45-4e6e-b1ec-7b0e65171bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 128])\n"
     ]
    }
   ],
   "source": [
    "image = image.squeeze().permute(1, 2, 0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec90946-dad7-42dd-97a4-a9e6537d8e6b",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0852dece-668e-42f6-93ed-68945d735a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation: Generating more data by applying random transformations to original images\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    ])\n",
    "\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "\"D:\\hossam\\Deep learnig\\Intermediate Deep Learning with PyTorch\\clouds\\clouds_train\",\n",
    "transform=train_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ebf34d-c542-4dc9-a5ee-0c86aa044407",
   "metadata": {},
   "source": [
    "# CNN Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac7e6d18-e557-4d4c-a6ae-88bb03194c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Define feature extractor\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        # Define classifier\n",
    "        self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "    \n",
    "    def forward(self, x):  \n",
    "        # Pass input through feature extractor and classifier\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f40d4d-6b03-4ca7-9f6f-7e19d63bc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation \n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAutocontrast(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f4000c8c-82e2-4981-b90f-8e88baa3a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read our train data \n",
    "dataset_train = ImageFolder(\n",
    "\"D:\\hossam\\Deep learnig\\Intermediate Deep Learning with PyTorch\\clouds\\clouds_train\",\n",
    "transform=train_transforms,\n",
    ")\n",
    "\n",
    "# read our test data \n",
    "dataset_test = ImageFolder(\n",
    "\"D:\\hossam\\Deep learnig\\Intermediate Deep Learning with PyTorch\\clouds\\clouds_test\",\n",
    "transform=train_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "591a02cb-ec12-47ea-b01d-755188b2af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders to iterate through batches\n",
    "dataloader_train = DataLoader(\n",
    "                        dataset_train,\n",
    "                        shuffle=True,\n",
    "                        batch_size=1,\n",
    "                        )\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "                        dataset_train,\n",
    "                        shuffle=True,\n",
    "                        batch_size=1,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9d1ae34-ab4a-4c49-9c38-9929b8c16c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "image, label = next(iter(dataloader_train))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20e3a997-1206-468e-99cc-62ced72ca79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "image = image.squeeze().permute(1, 2, 0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744cdac-a631-459b-a11f-c2ab42fd02f7",
   "metadata": {},
   "source": [
    "# Image classifier training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7f70cbf-25a3-43b0-af6f-fea769e50ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = Net(num_classes=7)\n",
    "\n",
    "# Image classifier training loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed25f26e-ec55-4af5-8cd8-9e9949c0df38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "epoch_loss = running_loss / len(dataloader_train)\n",
    "print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51322af4-08e6-48ad-b131-1a5ebee1e07b",
   "metadata": {},
   "source": [
    "<h1>Multi-class model evaluation</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355204da-4621-4929-8279-23cf06aadbb7",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-size:18px;\">\n",
    "Let's evaluate our cloud classifier with precision and recall to see how well it can classify the seven cloud types. In this multi-class classification task it is important how you average the scores over classes. Recall that there are four approaches:\n",
    "</p>\n",
    "\n",
    "<h3>1. Not averaging</h3>\n",
    "<p>Analyze the results per class individually.</p>\n",
    "\n",
    "<h3>2. Micro-averaging</h3>\n",
    "<p>Ignore the classes and compute the metrics globally.</p>\n",
    "\n",
    "<h3>3. Macro-averaging</h3>\n",
    "<p>Compute metrics per class and then average them.</p>\n",
    "\n",
    "<h3>4. Weighted-averaging</h3>\n",
    "<p>Like macro-averaging, but the average is weighted by class size.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0342ce93-550d-4ca0-b911-7f2495b33509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchmetrics import Recall , Precision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "24f3d048-d5f6-43f8-b576-32acd277390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_per_class = Recall(task=\"multiclass\", num_classes=7, average=None)\n",
    "recall_micro = Recall(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
    "recall_macro = Recall(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "recall_weighted = Recall(task=\"multiclass\", num_classes=7, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0d080bd5-185e-4fb1-b7ed-149693fc7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metric_precision = Precision(task='multiclass', num_classes=7, average=None)\n",
    "metric_recall = Recall(task='multiclass', num_classes=7, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "98f50306-7ad5-4b24-a08e-b3482dbc3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metric_precision_micro = Precision(task='multiclass', num_classes=7, average='micro')\n",
    "metric_recall_micro = Recall(task='multiclass', num_classes=7, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "48367889-382c-42ce-abac-ff8cfcc6ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metric_precision_macro = Precision(task='multiclass', num_classes=7, average='macro')\n",
    "metric_recall_macro = Recall(task='multiclass', num_classes=7, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cc0544a2-482f-43f1-a25f-3aed67bd4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metric_precision_weighted = Precision(task='multiclass', num_classes=7, average='weighted')\n",
    "metric_recall_weighted = Recall(task='multiclass', num_classes=7, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "91b895cb-c72b-4dd1-981f-ec6f9596ad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: tensor([0.5000, 0.6222, 0.7692, 0.6071, 0.6667, 0.2711, 0.4000])\n",
      "Recall: tensor([0.1818, 0.9333, 0.7143, 0.3736, 0.6015, 0.9184, 0.0328])\n"
     ]
    }
   ],
   "source": [
    "# evaluate Not AVG\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "        metric_recall(preds, labels)\n",
    "\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4390d8ea-c511-41f4-9997-d98863f47f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5126582384109497\n",
      "Recall: 0.5126582384109497\n"
     ]
    }
   ],
   "source": [
    "# evaluate micro\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision_micro(preds, labels)\n",
    "        metric_recall_micro(preds, labels)\n",
    "\n",
    "precision_micro = metric_precision_micro.compute()\n",
    "recall_micro = metric_recall_micro.compute()\n",
    "print(f\"Precision: {precision_micro}\")\n",
    "print(f\"Recall: {recall_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "07f0e500-1827-4dd6-9a04-7797a54ea086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5966891646385193\n",
      "Recall: 0.5579268932342529\n"
     ]
    }
   ],
   "source": [
    "# evaluate Macro\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision_macro(preds, labels)\n",
    "        metric_recall_macro(preds, labels)\n",
    "\n",
    "precision_macro = metric_precision_macro.compute()\n",
    "recall_macro = metric_recall_macro.compute()\n",
    "print(f\"Precision: {precision_macro}\")\n",
    "print(f\"Recall: {recall_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2c45a3e8-8a8e-4472-936a-299e79c631ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5126582384109497\n",
      "Recall: 0.5126582384109497\n"
     ]
    }
   ],
   "source": [
    "# evaluate metric weighted \n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision_weighted(preds, labels)\n",
    "        metric_recall_weighted(preds, labels)\n",
    "\n",
    "precision_micro = metric_precision_micro.compute()\n",
    "recall_micro = metric_recall_micro.compute()\n",
    "print(f\"Precision: {precision_micro}\")\n",
    "print(f\"Recall: {recall_micro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e200a-07f0-48e3-9e82-11839ee5af70",
   "metadata": {},
   "source": [
    "# Analyzing performance per class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e19424d9-098e-4584-9a89-0c6b7c76139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cirriform clouds': 0.5, 'clear sky': 0.6222222447395325, 'cumulonimbus clouds': 0.7692307829856873, 'cumulus clouds': 0.6071428656578064, 'high cumuliform clouds': 0.6666666865348816, 'stratiform clouds': 0.27108433842658997, 'stratocumulus clouds': 0.4000000059604645}\n"
     ]
    }
   ],
   "source": [
    "# Get precision per class\n",
    "precision_per_class = {\n",
    "    k: precision[v].item()  # Ensure 'precision' is lowercase\n",
    "    for k, v \n",
    "    in dataset_test.class_to_idx.items()\n",
    "}\n",
    "print(precision_per_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
